{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1024, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 372 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'C:/Users/Manpreet/Desktop/TensorFlow/DataSets/RockPaperScissors/train'\n",
    "val_dir = 'C:/Users/Manpreet/Desktop/TensorFlow/DataSets/RockPaperScissors/test'\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 128\n",
    ")\n",
    "\n",
    "val_data_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "validation_generator = val_data_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size = (150,150),\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20 steps, validate for 3 steps\n",
      "Epoch 1/40\n",
      "20/20 [==============================] - 16s 819ms/step - loss: 0.1444 - accuracy: 0.9484 - val_loss: 0.4835 - val_accuracy: 0.8387\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 17s 826ms/step - loss: 0.1850 - accuracy: 0.9321 - val_loss: 0.1240 - val_accuracy: 0.9543\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 17s 827ms/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.1615 - val_accuracy: 0.9489\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 16s 824ms/step - loss: 0.1550 - accuracy: 0.9452 - val_loss: 0.1202 - val_accuracy: 0.9543\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 16s 819ms/step - loss: 0.1505 - accuracy: 0.9456 - val_loss: 0.1106 - val_accuracy: 0.9624\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 16s 822ms/step - loss: 0.1493 - accuracy: 0.9460 - val_loss: 0.0766 - val_accuracy: 0.9651\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.1440 - accuracy: 0.9460 - val_loss: 0.1471 - val_accuracy: 0.9516\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 16s 817ms/step - loss: 0.1474 - accuracy: 0.9492 - val_loss: 0.2663 - val_accuracy: 0.8952\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 16s 818ms/step - loss: 0.1537 - accuracy: 0.9540 - val_loss: 0.2735 - val_accuracy: 0.9247\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 17s 841ms/step - loss: 0.1451 - accuracy: 0.9484 - val_loss: 0.0766 - val_accuracy: 0.9731\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 16s 811ms/step - loss: 0.1277 - accuracy: 0.9560 - val_loss: 0.0669 - val_accuracy: 0.9677\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 16s 817ms/step - loss: 0.1405 - accuracy: 0.9500 - val_loss: 0.1315 - val_accuracy: 0.9543\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 17s 832ms/step - loss: 0.1257 - accuracy: 0.9548 - val_loss: 0.0940 - val_accuracy: 0.9624\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.1252 - accuracy: 0.9556 - val_loss: 0.1739 - val_accuracy: 0.9462\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 16s 824ms/step - loss: 0.1453 - accuracy: 0.9540 - val_loss: 0.2029 - val_accuracy: 0.9435\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 17s 826ms/step - loss: 0.1189 - accuracy: 0.9571 - val_loss: 0.1606 - val_accuracy: 0.9435\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 16s 819ms/step - loss: 0.1093 - accuracy: 0.9611 - val_loss: 0.1939 - val_accuracy: 0.9462\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 16s 818ms/step - loss: 0.1201 - accuracy: 0.9528 - val_loss: 0.3552 - val_accuracy: 0.8656\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 16s 820ms/step - loss: 0.0954 - accuracy: 0.9683 - val_loss: 0.0783 - val_accuracy: 0.9651\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.1077 - accuracy: 0.9655 - val_loss: 0.0981 - val_accuracy: 0.9651\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 16s 817ms/step - loss: 0.1221 - accuracy: 0.9544 - val_loss: 0.0957 - val_accuracy: 0.9597\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 16s 823ms/step - loss: 0.1020 - accuracy: 0.9595 - val_loss: 0.1774 - val_accuracy: 0.9489\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 16s 821ms/step - loss: 0.1032 - accuracy: 0.9655 - val_loss: 0.7104 - val_accuracy: 0.8038\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 17s 829ms/step - loss: 0.1113 - accuracy: 0.9595 - val_loss: 0.1911 - val_accuracy: 0.9462\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 17s 851ms/step - loss: 0.1074 - accuracy: 0.9647 - val_loss: 0.1620 - val_accuracy: 0.9516\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 16s 814ms/step - loss: 0.0922 - accuracy: 0.9671 - val_loss: 0.0893 - val_accuracy: 0.9597\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 17s 829ms/step - loss: 0.1038 - accuracy: 0.9647 - val_loss: 0.2200 - val_accuracy: 0.9409\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 17s 830ms/step - loss: 0.0895 - accuracy: 0.9698 - val_loss: 0.2010 - val_accuracy: 0.9435\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 17s 827ms/step - loss: 0.0879 - accuracy: 0.9683 - val_loss: 0.1692 - val_accuracy: 0.9462\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 16s 814ms/step - loss: 0.1110 - accuracy: 0.9651 - val_loss: 0.2175 - val_accuracy: 0.9435\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 16s 817ms/step - loss: 0.0920 - accuracy: 0.9675 - val_loss: 0.1158 - val_accuracy: 0.9543\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.0811 - accuracy: 0.9722 - val_loss: 0.0969 - val_accuracy: 0.9570\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 16s 820ms/step - loss: 0.0892 - accuracy: 0.9718 - val_loss: 0.2138 - val_accuracy: 0.9462\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 16s 821ms/step - loss: 0.0767 - accuracy: 0.9730 - val_loss: 0.1711 - val_accuracy: 0.9435\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 17s 830ms/step - loss: 0.0830 - accuracy: 0.9679 - val_loss: 0.1347 - val_accuracy: 0.9543\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 17s 834ms/step - loss: 0.0925 - accuracy: 0.9734 - val_loss: 0.5006 - val_accuracy: 0.8575\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 16s 808ms/step - loss: 0.0620 - accuracy: 0.9770 - val_loss: 0.2368 - val_accuracy: 0.9409\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 16s 818ms/step - loss: 0.1030 - accuracy: 0.9671 - val_loss: 0.1944 - val_accuracy: 0.9462\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.0767 - accuracy: 0.9738 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 16s 816ms/step - loss: 0.0854 - accuracy: 0.9687 - val_loss: 0.2044 - val_accuracy: 0.9462\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=40, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paper\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "path = 'C:/Users/Manpreet/Desktop/TensorFlow/DataSets/RockPaperScissors/rps-validation/Paper.jpg'\n",
    "\n",
    "#for fn in uploaded.keys():\n",
    "\n",
    "#     path = fn\n",
    "img = image.load_img(path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "labels = sorted(['Rock', 'Paper', 'Scissors'])\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "\n",
    "#print(classes[0])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for i in range(0,len(classes[0])):\n",
    "    if(classes[0][i] == 1):\n",
    "        print(labels[i])\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
